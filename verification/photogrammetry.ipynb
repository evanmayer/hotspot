{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "from matplotlib.patches import Circle, Rectangle\n",
    "import numba\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from scipy import spatial\n",
    "from scipy import signal\n",
    "from scipy import ndimage\n",
    "from scipy import optimize\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_target(w: float, h: float, dpi: int, loc: str, plot=False):\n",
    "    '''\n",
    "    Generate an image of a photogrammetry target.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    w\n",
    "        total image width, m\n",
    "    h\n",
    "        total image height, m\n",
    "    dpi\n",
    "        output image dpi, converts between matrix coordinates and real width\n",
    "    loc\n",
    "        [SW, NW, SE, NE, raft] generates a different pattern for each loc\n",
    "    '''\n",
    "    IN_TO_METERS = 0.0254\n",
    "    w_in = w / IN_TO_METERS\n",
    "    h_in = h / IN_TO_METERS\n",
    "    w_px = np.round(w_in * dpi).astype(int)\n",
    "    h_px = np.round(h_in * dpi).astype(int)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(w_in, h_in)\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(left=0., right=1., top=1., bottom=0.)\n",
    "\n",
    "    pattern_size = 8\n",
    "    pattern = np.random.choice([0.05,0.95], size=(pattern_size,pattern_size))\n",
    "    pattern[0][0] = 0\n",
    "    pattern[pattern_size - 1][pattern_size - 1] = 1\n",
    "    ax.imshow(ndimage.zoom(pattern, h_px / pattern_size, order=0), cmap='Greys')\n",
    "\n",
    "    # center cross\n",
    "    c_size = dpi * 0.01 / IN_TO_METERS # 10 cm\n",
    "    c_thick = dpi * 0.001 / IN_TO_METERS # 1 mm\n",
    "\n",
    "    ax.add_patch(Rectangle((w_px / 2 - c_size / 2, h_px / 2 - c_thick / 2), c_size, c_thick, color='silver')) # horz\n",
    "    ax.add_patch(Rectangle((w_px / 2 - c_thick / 2, h_px / 2 - c_size / 2), c_thick, c_size, color='silver')) # vert\n",
    "    ax.add_patch(Rectangle((w_px / 2 - c_size / 2, h_px / 2 - c_thick / 4), c_size, c_thick / 2, color='k')) # horz\n",
    "    ax.add_patch(Rectangle((w_px / 2 - c_thick / 4, h_px / 2 - c_size / 2), c_thick / 2, c_size, color='k')) # vert\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim([0, w_px])\n",
    "    ax.set_ylim([0, h_px])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    fig.savefig(f'{loc}_target.png')\n",
    "    if not plot:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only run this if you need to re-generate photogrammetry targets.\n",
    "np.random.seed(77777) # generate same noise pattern every time\n",
    "gen_locs = ['SW', 'NW', 'NE', 'SE', 'raft']\n",
    "TARGET_W = 0.03 # 30 mm\n",
    "TARGET_H = TARGET_W\n",
    "# for loc in gen_locs:\n",
    "    # gen_target(TARGET_W, TARGET_H, 300, loc, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_camera(image_dir, plot=False):\n",
    "    # https://learnopencv.com/camera-calibration-using-opencv/\n",
    "    '''\n",
    "    The general idea is to take a set of test images with a chessboard pattern\n",
    "    (6x9, i.e. 5x8 intersections) to calculate the distortion parameters of the\n",
    "    camera/lens combo being used. This will be used to undo distortion effects\n",
    "    before we can undo projection effects.\n",
    "    '''\n",
    "    objpoints = [] # the chessboard vertex locations in the plane of the board\n",
    "    imgpoints = [] # the chessboard vertex locations in the image space\n",
    "    \n",
    "    prev_img_shape = None\n",
    "\n",
    "    for fname in sorted(glob.glob(os.path.join(image_dir, '**.jpg'), recursive=True)):\n",
    "        # do camera calibration from chessboard images\n",
    "        im = image.imread(fname)\n",
    "        im = np.rot90(im, k=-1) # may not need this, depending on source of images.\n",
    "        gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, CHESSBOARD, cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "        print(f'Camera calibration corner finding in {fname}:', ret)\n",
    "        # we will use the img plane points for camera calibration if we successfully found chessboard corners.\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            corners2 = cv2.cornerSubPix(gray, corners, (5,5),(-1,-1), criteria)\n",
    "            imgpoints.append(corners2)\n",
    "            im = cv2.drawChessboardCorners(gray, CHESSBOARD, corners2, ret)\n",
    "        \n",
    "        if plot:\n",
    "            plt.figure()\n",
    "            plt.imshow(im)\n",
    "            ax = plt.gca()\n",
    "            ax.set_aspect('equal')\n",
    "\n",
    "    # Do the actual camera calibration with all the data we gathered.\n",
    "    h,w = im.shape[:2]\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    optimal_camera_matrix, roi = cv2.getOptimalNewCameraMatrix(\n",
    "        mtx,\n",
    "        dist, \n",
    "        (w,h), \n",
    "        1, \n",
    "        (w,h)\n",
    "    )\n",
    "\n",
    "    return mtx, dist, optimal_camera_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xcorr_prep(im):\n",
    "    '''\n",
    "    Helper function to apply pre-processing that makes cross-correlation work\n",
    "    '''\n",
    "    im_corr = np.sum(im.astype(np.float64), axis=2) # ensure single channel\n",
    "    im_corr /= im_corr.max() # normalize\n",
    "    im_corr -= np.mean(im_corr) # detrend\n",
    "    return im_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_template(template_filename, im_warped, avg_px_per_m, ax=None):\n",
    "    '''\n",
    "    Returns the pixel coordinates of the best-cross-corr match of the template image in im_warped,\n",
    "    which ought to be a lens-distortion-free, camera-angle-projection-free image.\n",
    "    avg_px_per_m is needed to scale the target's known size in m to the image's pixel scale.\n",
    "    '''\n",
    "    im_tmp = image.imread(template_filename)\n",
    "    # number of pixels in a shape with 30mm span:\n",
    "    target_px = avg_px_per_m * 0.03\n",
    "    tmp_px = im_tmp.shape[0]\n",
    "    # zoom the template to the right size in pixels\n",
    "    tmp = ndimage.zoom(im_tmp, target_px / tmp_px)\n",
    "    a = xcorr_prep(im_warped)\n",
    "    b = xcorr_prep(tmp)\n",
    "    xcorr = signal.fftconvolve(\n",
    "        a,\n",
    "        b[::-1, ::-1],\n",
    "        mode='valid'\n",
    "    )\n",
    "    y,x = np.unravel_index(np.argmax(xcorr), xcorr.shape)\n",
    "    xfound = x + tmp.shape[0] / 2\n",
    "    yfound = y + tmp.shape[1] / 2\n",
    "\n",
    "    if ax:\n",
    "        ax.imshow(a)\n",
    "        ax.scatter(xfound, yfound, label=template_filename)\n",
    "\n",
    "    return xfound, yfound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_targets(image_dir, mtx, dist, optimal_camera_matrix, targets=[], plot=False):\n",
    "    '''\n",
    "    After we get the camera matrix, let's use it to undo distortion in all test images,\n",
    "    re-find chessboard corners, then find a homographic transform of the undistorted\n",
    "    chessboard corners to the ideal, rectified plane of the chessboard (the\n",
    "    \"bird's-eye\" view of it).\n",
    "    Use that and information of how far apart the chessboard intersections really are\n",
    "    to calculate a px-to-m conversion.\n",
    "    Finally, do a cross-correlation to find the location of all target images, in m,\n",
    "    relative to the chessboard 0,0 intersection.\n",
    "    '''\n",
    "    files = sorted(glob.glob(os.path.join(image_dir, '**.jpg'), recursive=True))\n",
    "\n",
    "    image_data = {}\n",
    "    px_per_ms = []\n",
    "    for file in files:\n",
    "        # use camera cal matrix to de-distort all images\n",
    "        im = image.imread(file)\n",
    "        im = np.rot90(im, k=-1)\n",
    "        undistorted_image = cv2.undistort(\n",
    "            im,\n",
    "            mtx,\n",
    "            dist,\n",
    "            None, \n",
    "            optimal_camera_matrix\n",
    "        )\n",
    "        # if you get funny results (fake ring images with data from the center around the perimeter),\n",
    "        # consider this: https://answers.opencv.org/question/28438/undistortion-at-far-edges-of-image/\n",
    "        # lenses with nonlinear distortion parameters from the center to the edge present problems to\n",
    "        # the algorithm. apparently it can be mitigated by digital zoom/cropping out data from the\n",
    "        # corners of the sensor. this effect was very noticeable on my iPhone 8 camera.\n",
    "\n",
    "        # re-find chessboard corners in undistorted image\n",
    "        gray = cv2.cvtColor(undistorted_image, cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, CHESSBOARD, cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "        print(f'Corner detection after de-distortion in {file}:', ret)\n",
    "        if ret == True:\n",
    "            corners2 = cv2.cornerSubPix(gray, corners, (5,5),(-1,-1), criteria)\n",
    "            undistorted_image_corners = cv2.drawChessboardCorners(undistorted_image, CHESSBOARD, corners2, ret)\n",
    "        else:\n",
    "            continue\n",
    "        # if plot:\n",
    "        #     plt.figure()\n",
    "        #     ax = plt.axes()\n",
    "        #     ax.set_title('After de-distortion')\n",
    "        #     ax.set_aspect('equal')\n",
    "        #     ax.grid(True)\n",
    "        #     ax.imshow(undistorted_image_corners)\n",
    "\n",
    "        # find the homographic transform that undistorts the found chessboard corners into the rectified, \"bird's eye\" view of the chessboard.\n",
    "        this_img = corners2\n",
    "        # magic number: homographic transform for de-projection sometimes makes resulting image really tiny for some reason.\n",
    "        # if we didn't scale it back up, we'd have only a few pixels across each chessboard intersection, degrading the\n",
    "        # quality of the subpixel refinement and eventually the template location xcorr too.\n",
    "        sf = 3000.\n",
    "        h, status = cv2.findHomography(\n",
    "            this_img[:,0,:],\n",
    "            objp[0,:,:2] * sf + corners2[0][0]\n",
    "        )\n",
    "        # deproject chessboard points\n",
    "        corners_warped = cv2.perspectiveTransform(\n",
    "            corners2,\n",
    "            h\n",
    "        )\n",
    "        im_warped = cv2.warpPerspective(\n",
    "            undistorted_image,\n",
    "            h,\n",
    "            (undistorted_image.shape[1], undistorted_image.shape[0])\n",
    "        )\n",
    "        \n",
    "        # if plot:\n",
    "        #     plt.figure()\n",
    "        #     ax = plt.axes()\n",
    "        #     ax.set_title('After de-projection')\n",
    "        #     ax.set_aspect('equal')\n",
    "        #     ax.grid(True)\n",
    "        #     ax.imshow(im_warped)\n",
    "\n",
    "        # locate chessboard corners in deprojected image to calculate pixel scale\n",
    "        # gray = cv2.cvtColor(im_warped, cv2.COLOR_BGR2GRAY)\n",
    "        # ret, corners = cv2.findChessboardCorners(\n",
    "        #     gray,\n",
    "        #     CHESSBOARD,\n",
    "        #     cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_NORMALIZE_IMAGE\n",
    "        # )\n",
    "        # print(f'Corner detection after de-projection in {file}:', ret)\n",
    "        # if ret == True:\n",
    "        #     corners_warped = cv2.cornerSubPix(gray, corners, (5,5),(-1,-1), criteria)\n",
    "        #     im_warped_corners = cv2.drawChessboardCorners(im_warped, CHESSBOARD, corners_warped, ret)\n",
    "        #     im_warped_corners_grey = cv2.cvtColor(im_warped_corners, cv2.COLOR_BGR2GRAY)\n",
    "        # else:\n",
    "        #     continue\n",
    "\n",
    "        # calc pixel scale: get pairs of euclidean distances along each axis.\n",
    "        # this leaves some information on the table, but is simple and there\n",
    "        # are enough pairs that the average should be good to submm precision across ~1 m.\n",
    "        found_corners = corners_warped[:,0,:].reshape((CHESSBOARD[1], CHESSBOARD[0], 2))\n",
    "        dists0 = np.array([])\n",
    "        for i in range(found_corners.shape[0]):\n",
    "            d = np.diff(found_corners[i,:,:], axis=0)\n",
    "            dists0 = np.concatenate([dists0, np.sqrt((d ** 2).sum(axis=1))])\n",
    "        dists1 = np.array([])\n",
    "        for j in range(found_corners.shape[1]):\n",
    "            d = np.diff(found_corners[:,j,:], axis=0)\n",
    "            dists1 = np.concatenate([dists1, np.sqrt((d ** 2).sum(axis=1))])\n",
    "        dists = np.concatenate([dists0, dists1])\n",
    "        avg_spacing = np.mean(np.abs(dists))\n",
    "        std_spacing = np.std(np.abs(dists))\n",
    "        px_per_m = avg_spacing / SQUARE_SIZE\n",
    "        px_per_ms.append(px_per_m)\n",
    "        plt.figure()\n",
    "        # ax = plt.axes()\n",
    "        # ax.plot(dists)\n",
    "\n",
    "        # find pixel locs of all targets\n",
    "        target_dir = os.curdir\n",
    "        target_locs = {}\n",
    "        target_locs['chessboard_origin'] = tuple(corners2[0][0].astype(float))\n",
    "        if plot:\n",
    "            plt.figure()\n",
    "            ax = plt.axes()\n",
    "        else:\n",
    "            ax = None\n",
    "        for target in targets:\n",
    "            x,y = find_template(os.path.join(target_dir, target + '.png'), im_warped, px_per_m, ax=ax)\n",
    "            target_locs[target] = (x,y)\n",
    "        if plot:\n",
    "            ax.legend(loc='best')\n",
    "\n",
    "        m_per_inch = 0.0254\n",
    "        for target in [item for item in targets if 'raft_target' not in item]:\n",
    "            print(f'distance of {target} from raft:', np.linalg.norm(np.array(target_locs[target]) - np.array(target_locs['raft_target'])) / px_per_m / m_per_inch, 'in')\n",
    "\n",
    "        # save off some data\n",
    "        image_data[file] = {}\n",
    "        image_data[file]['px_per_m'] = px_per_m\n",
    "        image_data[file]['target_locs'] = target_locs\n",
    "\n",
    "    frac_err = np.std(px_per_ms) / np.mean(px_per_ms)\n",
    "    avg_px_per_m = np.mean(px_per_ms)\n",
    "    image_data['source dir'] = os.path.abspath(image_dir)\n",
    "    image_data['avg_px_per_m'] = avg_px_per_m\n",
    "    # print('std error induced by pixel cal across span of .7m:', 0.7 * frac_err)\n",
    "\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global stuff\n",
    "CHESSBOARD = (5,8)\n",
    "SQUARE_SIZE = 0.0254 # 25 mm\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "# the set of chessboard corner coords in the plane of the chessboard\n",
    "objp = np.zeros((1, CHESSBOARD[0] * CHESSBOARD[1], 3), np.float32)\n",
    "objp[0,:,:2] = np.mgrid[0:CHESSBOARD[0], 0:CHESSBOARD[1]].T.reshape(-1, 2) * SQUARE_SIZE\n",
    "\n",
    "# calibrate the camera for distortion\n",
    "mtx, dist, optimal_camera_matrix = calibrate_camera('input', plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "image_data = find_targets('input', mtx, dist, optimal_camera_matrix, targets=['raft_target', 'SW_target', 'SE_target', 'NW_target', 'NE_target'], plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c78355426ab29dd466d6c9fb37ae1bcdf5ce1e23673f940012e871d663c0200"
  },
  "kernelspec": {
   "display_name": "Python 3.6.15 64-bit ('hotspot': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
